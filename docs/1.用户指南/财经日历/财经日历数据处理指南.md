# 财经日历数据处理指南

## 系统概述

本指南旨在全面介绍财经日历数据处理系统的使用方法、系统架构和核心功能。该系统通过自动化的工作流脚本和灵活的配置文件，帮助用户获取、筛选、处理财经事件数据，并支持与 MetaTrader 5 (MT5) 平台集成，最终服务于量化交易策略的开发、回测和实盘应用。

## 系统架构与核心组件

系统采用基于配置文件驱动的工作流脚本模式。核心组件分布在以下主要目录中：

*   **`config/`**: 存放核心配置文件。
    *   `workflow_config.yaml`: 定义所有工作流的行为、参数、路径和筛选规则。★ (核心配置)
    *   `logging_config.yaml`: 配置日志记录格式和级别。
    *   `mt5_config.yaml`: (如果存在) 可能包含 MT5 连接的详细配置。
*   **`economic_data_sources/tasks/`**: 包含顶层的工作流执行脚本。
    *   `run_history_workflow.py`: 处理历史数据的入口脚本。★
    *   `run_realtime_workflow.py`: 处理实时/前瞻数据的入口脚本。★
    *   `WORKFLOW_README.md`: 对工作流配置和执行的详细说明。
*   **`src/`**: 包含核心的 Python 源代码。
    *   `src/config/`: 负责加载、验证和解析 YAML 配置文件，提供配置对象的访问。
    *   `src/data/`: 处理数据的输入和输出 (loader.py, exporter.py)。
    *   `src/event_filter/`: 实现核心的事件筛选逻辑 (logic.py, utils.py, constants.py)。
    *   `src/utils/`: (如果存在) 可能包含项目通用的辅助工具函数。
    *   `src/paths.py`: (通常在项目根目录或 `src` 下) 定义和管理项目内的各种文件路径。
*   **`data/`**: 数据存储目录，包含原始数据、处理后数据和筛选后数据。
*   **`logs/`**: 存放工作流执行日志文件。

## 核心工作流与执行

系统主要通过两个脚本处理不同类型的数据：

1.  **历史数据处理 (`run_history_workflow.py`)**:
    *   **目的**: 处理历史财经日历数据，用于策略回测和分析。
    *   **输入**: 通常读取 `data/calendar/processed/history/economic_calendar_history.csv` (可在 `workflow_config.yaml` 中通过 `input_override` 配置)。
    *   **配置段**: `filtering_history` (在 `workflow_config.yaml` 中)。
    *   **执行**: `python economic_data_sources/tasks/run_history_workflow.py`

2.  **实时/前瞻数据处理 (`run_realtime_workflow.py`)**:
    *   **目的**: 处理最新的、通常是未来几天的财经日历数据，用于实盘交易参考。
    *   **输入**: 通常读取 `data/calendar/raw/live/upcoming.csv` (此文件需由其他先行流程生成或下载)。
    *   **配置段**: `filtering_realtime` (或类似名称，在 `workflow_config.yaml` 中)。
    *   **执行**: `python economic_data_sources/tasks/run_realtime_workflow.py`

**通用执行步骤**: 

1.  **配置**: 打开 `config/workflow_config.yaml`，找到对应工作流的配置段 (`filtering_history` 或 `filtering_realtime`)，根据需求修改筛选规则、路径、导出格式、MT5 集成等选项。
2.  **运行**: 在项目根目录下，使用激活的 Python 环境执行相应的 `.py` 脚本。
3.  **检查结果**: 查看配置的输出路径下的文件、指定的 MT5 目录（如果配置了复制）以及 `logs/` 目录下的日志文件。

## 配置核心 (`config/workflow_config.yaml`)

`workflow_config.yaml` 是驱动整个系统的核心，以 YAML 格式定义了几乎所有的可配置行为。关键部分包括：

*   **`paths`**: 定义基础数据目录、日志目录等。
*   **`mt5_configs`**: （可选）定义一个或多个 MT5 实例的配置，主要是 `MQL5/Files` 目录路径。
*   **`filtering_history` / `filtering_realtime`**: 各工作流的特定配置，包含：
    *   `input_override` / 输入源说明
    *   `output_path`: 输出路径和文件名。
    *   `export_format`: 输出格式 (`csv`, `json`, `mt5`)。
    *   筛选规则: `min_importance`, `use_keywords`, `keywords`, `target_currencies`, `start_time`, `end_time` 等。
    *   `add_market_open`: 是否添加开盘事件 (`true`/`false`)。
    *   `copy_to_mt5_dir`: 目标 MT5 `MQL5/Files` 路径 (可选)。
    *   `mt5_config_name`: 使用哪个 `mt5_configs` 定义。

**详细配置项请参考 `workflow_config.yaml` 文件内的注释和 `economic_data_sources/tasks/WORKFLOW_README.md` 文档。**

## 核心数据处理流程步骤

工作流脚本执行时，内部通常按以下步骤处理数据：

1.  **初始化**: 设置路径和日志。
2.  **加载配置**: 读取并验证 `workflow_config.yaml`。
3.  **环境检查**: (可选) 检查所需目录等是否存在。
4.  **加载数据**: 从输入文件加载数据到 Pandas DataFrame (`loader.py`)。
5.  **筛选与处理**: 应用配置的规则进行筛选 (`logic.py`)，如果配置，添加开盘事件 (`utils.py`)。
6.  **排序**: 对结果排序。
7.  **导出**: 按配置格式导出数据 (`exporter.py`)。
8.  **MT5复制**: (可选) 复制文件到 MT5 目录。
9.  **记录日志**: 记录执行结果。

## 数据格式规范

最终导出的数据（特别是 CSV 格式）遵循标准列结构：
`Date, Weekday, Time, Currency, Importance, Event, Actual, Forecast, Previous`

*   `Weekday`: 中文星期。
*   `Time`: 通常为北京时间 (HH:MM)。
*   `Importance`: 可能为空字符串或星级描述。
*   空值: 表示为 `""`。
*   编码: CSV/JSON 通常为 `utf-8-sig`，`mt5` 格式会额外生成 `gbk` 版本。

## MT5 集成

通过 `workflow_config.yaml` 实现：

1.  **设置 `export_format: mt5`**: 生成 MT5 优化格式的 CSV 文件（两种编码）。
2.  **设置 `copy_to_mt5_dir` 和 `mt5_config_name`**: 自动将指定格式的输出文件复制到 MT5 的 `MQL5/Files` 目录。

## 日志与错误处理

*   日志记录在 `logs/history_workflow.log` 和 `logs/realtime_workflow.log`。
*   执行错误会输出到控制台和日志文件。
*   常见问题排查：检查日志、核对 `workflow_config.yaml` 配置（特别是路径）、确认输入文件存在且格式正确、检查 Python 环境和依赖。

## 高级使用与扩展

*   深入理解 `workflow_config.yaml` 可实现高度定制化。
*   阅读 `src/` 目录源码可了解具体实现细节。
*   导出的数据可用于 Pandas、数据库等进行二次分析。
*   系统的模块化设计允许在 `src/` 下扩展新的处理逻辑或导出器（需要修改代码）。 